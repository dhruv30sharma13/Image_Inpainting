{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import torchvision\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7aa299",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagesPath = input(\"Enter path to folder containing unmasked images: \")\n",
    "imgs = os.listdir(ImagesPath)\n",
    "TrainImages = []\n",
    "\n",
    "for im in imgs:\n",
    "    img = cv2.imread(os.path.join(ImagesPath, im))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    TrainImages.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentSet(Dataset):\n",
    "    def __init__(self, X, y, dim = (256, 256), n_channels = 3):\n",
    "        super(AugmentSet, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_input, y_input = self.__data_generator(idx)\n",
    "        return X_input, y_input\n",
    "    \n",
    "    def __create_masked_image(self, img):\n",
    "                height = 256; width = 256\n",
    "\n",
    "        mask = np.zeros((height, width, 3), np.uint8) * 255\n",
    "\n",
    "        # Draw random black lines\n",
    "        num_lines = np.random.randint(5, 10)\n",
    "        for i in range(num_lines):\n",
    "            thickness = np.random.randint(1, 5)\n",
    "            x1, y1 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "            x2, y2 = np.random.randint(0, width), np.random.randint(0, height)\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), (255, 255, 255), thickness)\n",
    "        # Draw random black curves\n",
    "\n",
    "        num_curves = np.random.randint(2, 4)\n",
    "        for i in range(num_curves):\n",
    "            points = np.random.randint(0, min(height, width), size=(4, 2))\n",
    "            thickness = np.random.randint(1, 5)\n",
    "            angle = np.random.randint(0, 180)\n",
    "            arc_length = np.random.randint(20, 80)\n",
    "            curve_center = np.mean(points[:2], axis=0)\n",
    "            start_angle = np.arctan2(points[0][1] - curve_center[1], points[0][0] - curve_center[0]) * 180 / np.pi\n",
    "            end_angle = np.arctan2(points[1][1] - curve_center[1], points[1][0] - curve_center[0]) * 180 / np.pi\n",
    "            cv2.ellipse(mask, tuple(curve_center.astype(int)), (arc_length, arc_length), angle, start_angle, end_angle, (255, 255, 255), thickness)\n",
    "\n",
    "            curve_center = np.mean(points[2:], axis=0)\n",
    "            start_angle = np.arctan2(points[2][1] - curve_center[1], points[2][0] - curve_center[0]) * 180 / np.pi\n",
    "            end_angle = np.arctan2(points[3][1] - curve_center[1], points[3][0] - curve_center[0]) * 180 / np.pi\n",
    "            cv2.ellipse(mask, tuple(curve_center.astype(int)), (arc_length, arc_length), angle, start_angle, end_angle, (255, 255, 255), thickness)\n",
    "\n",
    "\n",
    "        # Draw random black circles\n",
    "        num_circles = np.random.randint(5, 10)\n",
    "        for i in range(num_circles):\n",
    "            radius = np.random.randint(1, 20)\n",
    "            thickness = -1\n",
    "            x, y = np.random.randint(0, width), np.random.randint(0, height)\n",
    "            cv2.circle(mask, (x, y), radius, (255, 255, 255), thickness)\n",
    "        \n",
    "        return masked_image, mask\n",
    "    \n",
    "    def __data_generator(self, idx):\n",
    "        img_copy = self.X[idx].copy()\n",
    "        masked_img, mask = self.__create_masked_image(img_copy)\n",
    "        masked_img = (torch.tensor((masked_img/255.0).astype(\"float32\")).reshape((3, self.X[idx].shape[0], self.X[idx].shape[1])))\n",
    "        mask = (torch.tensor((mask/255.0).astype(\"float32\")).reshape((3, self.X[idx].shape[0], self.X[idx].shape[1])))\n",
    "        y_img = (torch.tensor((self.y[idx]/255.0).astype(\"float32\")).reshape((3, self.X[idx].shape[0], self.X[idx].shape[1])))\n",
    "        \n",
    "        return [masked_img, mask], y_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(TrainImages)\n",
    "AugmentedDataset = AugmentSet(TrainImages, TrainImages, (256, 256), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778af9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(AugmentedDataset, batch_size = 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def downsample(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            return layers\n",
    "\n",
    "        def upsample(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.ConvTranspose2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n",
    "            layers.append(nn.ELU())\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *downsample(channels, 64, normalize=False),\n",
    "            *downsample(64, 128),\n",
    "            *downsample(128, 256),\n",
    "            *downsample(256, 512),\n",
    "            *upsample(512, 256),\n",
    "            *upsample(256, 128),\n",
    "            *upsample(128, 64),\n",
    "            *upsample(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01284034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, stride, normalize):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = channels\n",
    "        for out_filters, stride, normalize in [(64, 2, False), (128, 2, True), (256, 2, True), (512, 1, True)]:\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, stride, normalize))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(channels = 3).to(device)\n",
    "reckt = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f55bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function created to rebuild masked area\n",
    "class ReconstructLossL2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReconstructLossL2, self).__init__()\n",
    "        \n",
    "    def forward(self, mask, y_pred, ipt):\n",
    "        diff = ipt - y_pred\n",
    "        loss = torch.mul(mask, diff)\n",
    "        l1loss = torch.sum(torch.abs(loss))\n",
    "    \n",
    "        return l1loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace masked area in image with that predicted by the model\n",
    "def get_filled_img(mask, masked_img, output):\n",
    "    mi = np.array(masked_img.cpu()).reshape(256, 256, 3)\n",
    "    m = np.array(mask.cpu()).reshape(256, 256, 3)\n",
    "    o = np.array(output.cpu().detach()).reshape(256, 256, 3)\n",
    "    mt = cv2.cvtColor(m, cv2.COLOR_BGR2RGB)\n",
    "    mt = cv2.cvtColor(mt, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    ex = cv2.bitwise_and(o,o,mask=mt.astype(\"uint8\"))    \n",
    "    img = cv2.add(ex, mi)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c4301",
   "metadata": {},
   "source": [
    "## Training Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76293ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model files, trained earlier on local GPU of laptop\n",
    "reckt.load_state_dict(torch.load(\"generator_ckpt.pt\"))\n",
    "disc.load_state_dict(torch.load(\"discriminator_ckpt.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64b8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "pixelwise_loss = ReconstructLossL2()\n",
    "adversarial_loss = nn.MSELoss()\n",
    "optimizer_g = torch.optim.Adam(reckt.parameters(), lr = 0.0004, betas = (0.1, 0.99))\n",
    "optimizer_d = torch.optim.Adam(disc.parameters(), lr = 0.0004, betas = (0.1, 0.999))\n",
    "mask_size = 256\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "patch_h, patch_w = int(mask_size / 2 ** 3), int(mask_size / 2 ** 3)\n",
    "patch = (1, patch_h, patch_w)\n",
    "g_loss_items = []\n",
    "d_loss_items = []\n",
    "\n",
    "reckt.train()\n",
    "disc.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_g_loss = 0\n",
    "    running_d_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        masked_img = inputs[0]\n",
    "        mask = inputs[1]\n",
    "        masked_img, labels, mask = masked_img.to(device), labels.to(device), mask.to(device)\n",
    "        \n",
    "        valid = Variable(Tensor(labels.shape[0], *patch).fill_(1.0), requires_grad=False).to(device)\n",
    "        fake = Variable(Tensor(labels.shape[0], *patch).fill_(0.0), requires_grad=False).to(device)\n",
    "        \n",
    "        # training the generator network\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        outputs = reckt(masked_img)  \n",
    "        oos = outputs.detach().clone()\n",
    "        \n",
    "        # getting proper output images formed from generator output\n",
    "        a = []\n",
    "\n",
    "        for (m, mi, o) in zip(mask, masked_img, outputs):\n",
    "            a.append(get_filled_img(m, mi, o))\n",
    "\n",
    "        a = torch.tensor(np.array(a))\n",
    "        gen_predicts = a.reshape(outputs.shape[0], 3, 256, 256)\n",
    "        \n",
    "        g_pixel = pixelwise_loss(mask, outputs, labels)  \n",
    "        g_adv = adversarial_loss(disc(gen_predicts.to(device)), valid)\n",
    "        g_loss = 1000 * g_adv + 0.5 * g_pixel\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        running_g_loss += g_loss.item()\n",
    "        \n",
    "        # training the discriminator network\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        fake_loss = adversarial_loss(disc(gen_predicts.to(device)), fake)\n",
    "        real_loss = adversarial_loss(disc(labels.to(device)), valid)\n",
    "        d_loss = 0.5 * (fake_loss + real_loss)\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        running_d_loss += d_loss.item()\n",
    "\n",
    "        g_loss_items.append(g_loss.item())\n",
    "        d_loss_items.append(d_loss.item())\n",
    "        \n",
    "        if (i % 100 == 99):\n",
    "            print(f\"Epoch - {epoch + 1}, iteration = {i + 1}, generator-loss: {running_g_loss / 100:.3f}, discriminator-loss: {running_d_loss / 100:.3f}\")#\", acc: {running_acc / 100:.3f}\")\n",
    "            running_g_loss = 0\n",
    "            running_d_loss = 0\n",
    "            torch.save(reckt.state_dict(), \"generator_ckpt.pt\")\n",
    "            torch.save(disc.state_dict(), \"discriminator_ckpt.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ec97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebce9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss plot\n",
    "g_l_dict = {\"iterations\" : list(range(len(g_loss_items))), \"generator_loss\" : g_loss_items}\n",
    "generator_loss_df = pd.DataFrame(g_l_dict)\n",
    "sns.lineplot(data = generator_loss_df, x = 'iterations', y = 'generator_loss', color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator loss plot\n",
    "d_l_dict = {\"iterations\" : list(range(len(d_loss_items))), \"discriminator_loss\" : d_loss_items}\n",
    "discriminator_loss_df = pd.DataFrame(d_l_dict)\n",
    "sns.lineplot(data = discriminator_loss_df, x = 'iterations', y = 'discriminator_loss', color = 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21edad7",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SamplePath = input(\"Enter path to testing data containing masked, painted images and masks in same format as in sample testing: \")\n",
    "sample_set_path = SamplePath\n",
    "imgs = os.listdir(sample_set_path)\n",
    "imgs.sort()\n",
    "imgs[0], imgs[1] = imgs[1], imgs[0] # to keep them in order... ensure proper order before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "label_imgs = []\n",
    "inpaints = []\n",
    "\n",
    "for img_name in imgs:\n",
    "    img_path = os.path.join(sample_set_path, img_name)\n",
    "    img_arr = cv2.imread(img_path)\n",
    "    if (\"mask\" in img_name):\n",
    "        masks.append(img_arr)\n",
    "    if (\"inpainted\" in img_name):\n",
    "        inpaints.append(img_arr)\n",
    "    else:\n",
    "        label_imgs.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(input(\"Enter index of image to paint upon: \"))\n",
    "res = reckt(torch.tensor((inpaints[index]/255).astype(\"float32\").reshape(1, 3, 256, 256)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(masks[index]).reshape(3, 256, 256)/255\n",
    "mi = torch.tensor(inpaints[index]).reshape(3, 256, 256)/255\n",
    "o = torch.tensor(res).reshape(3, 256, 256)\n",
    "\n",
    "mi = np.array(mi.cpu()).reshape(256, 256, 3)\n",
    "m = 1 - m\n",
    "m = np.array(m.cpu()).reshape(256, 256, 3)\n",
    "o = np.array(o.cpu().detach()).reshape(256, 256, 3)\n",
    "mt = cv2.cvtColor(m, cv2.COLOR_BGR2RGB)\n",
    "mt = cv2.cvtColor(mt, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "mt[mt > 0.8] = 1\n",
    "\n",
    "ex = cv2.bitwise_and(o,o,mask=mt.astype(\"uint8\"))\n",
    "mi[mt > 0.5] = 0\n",
    "img = cv2.add(ex, mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d310e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res.cpu().detach().reshape(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.add(ex, mi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80278921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3eae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
